{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 19. RNN with Hamlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import nltk\n",
    "\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19.1 Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"gutenberg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[The Tragedie of Hamlet by William Shakespeare 1599]\n",
      "\n",
      "\n",
      "Actus Primus. Scoena Prima.\n",
      "\n",
      "Enter Barnardo and Francisco two Centinels.\n",
      "\n",
      "  Barnardo. Who's there?\n",
      "  Fran. Nay answer me: Stand & vnfold\n",
      "your selfe\n",
      "\n",
      "   Bar. Long liue the King\n",
      "\n",
      "   Fran. Barnardo?\n",
      "  Bar. He\n",
      "\n",
      "   Fran. You come most carefully vpon your houre\n",
      "\n",
      "   Bar. 'Tis now strook twelue, get thee to bed Francisco\n",
      "\n",
      "   Fran. For this releefe much thankes: 'Tis bitter cold,\n",
      "And I am sicke at heart\n",
      "\n",
      "   Barn. Haue you had quiet Guard?\n",
      "  Fran. Not\n"
     ]
    }
   ],
   "source": [
    "raw = nltk.corpus.gutenberg.raw(\"shakespeare-hamlet.txt\")\n",
    "print(raw[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19.2 Char to Dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2index = {}\n",
    "index2char = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for char in raw :\n",
    "    if char not in char2index.keys() :\n",
    "        char2index[char] = len(char2index)\n",
    "        index2char.append(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'[': 0,\n",
       " 'T': 1,\n",
       " 'h': 2,\n",
       " 'e': 3,\n",
       " ' ': 4,\n",
       " 'r': 5,\n",
       " 'a': 6,\n",
       " 'g': 7,\n",
       " 'd': 8,\n",
       " 'i': 9,\n",
       " 'o': 10,\n",
       " 'f': 11,\n",
       " 'H': 12,\n",
       " 'm': 13,\n",
       " 'l': 14,\n",
       " 't': 15,\n",
       " 'b': 16,\n",
       " 'y': 17,\n",
       " 'W': 18,\n",
       " 'S': 19,\n",
       " 'k': 20,\n",
       " 's': 21,\n",
       " 'p': 22,\n",
       " '1': 23,\n",
       " '5': 24,\n",
       " '9': 25,\n",
       " ']': 26,\n",
       " '\\n': 27,\n",
       " 'A': 28,\n",
       " 'c': 29,\n",
       " 'u': 30,\n",
       " 'P': 31,\n",
       " '.': 32,\n",
       " 'n': 33,\n",
       " 'E': 34,\n",
       " 'B': 35,\n",
       " 'F': 36,\n",
       " 'w': 37,\n",
       " 'C': 38,\n",
       " \"'\": 39,\n",
       " '?': 40,\n",
       " 'N': 41,\n",
       " ':': 42,\n",
       " '&': 43,\n",
       " 'v': 44,\n",
       " 'L': 45,\n",
       " 'K': 46,\n",
       " 'Y': 47,\n",
       " ',': 48,\n",
       " 'I': 49,\n",
       " 'q': 50,\n",
       " 'G': 51,\n",
       " 'M': 52,\n",
       " 'R': 53,\n",
       " '-': 54,\n",
       " 'D': 55,\n",
       " 'O': 56,\n",
       " 'x': 57,\n",
       " ';': 58,\n",
       " 'Q': 59,\n",
       " 'z': 60,\n",
       " '(': 61,\n",
       " ')': 62,\n",
       " 'V': 63,\n",
       " '!': 64,\n",
       " 'j': 65,\n",
       " 'Z': 66}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(char2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2vec = {}\n",
    "eye = np.eye(len(char2index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in char2index.keys() :\n",
    "    char2vec[item] = eye[char2index[item],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char2vec['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([char2vec[char] for char in raw])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19.3 Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters:\t\n",
    "# input_size – The number of expected features in the input x\n",
    "# hidden_size – The number of features in the hidden state h\n",
    "# num_layers – Number of recurrent layers. E.g., setting num_layers=2 would mean stacking two RNNs together to form a stacked RNN, with the second RNN taking in outputs of the first RNN and computing the final results. Default: 1\n",
    "# nonlinearity – The non-linearity to use. Can be either ‘tanh’ or ‘relu’. Default: ‘tanh’\n",
    "# bias – If False, then the layer does not use bias weights b_ih and b_hh. Default: True\n",
    "# batch_first – If True, then the input and output tensors are provided as (batch, seq, feature). Default: False\n",
    "# dropout – If non-zero, introduces a Dropout layer on the outputs of each RNN layer except the last layer, with dropout probability equal to dropout. Default: 0\n",
    "# bidirectional – If True, becomes a bidirectional RNN. Default: False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "#         self.rnn = nn.GRU(input_size,hidden_size,num_layers)\n",
    "        self.rnn = nn.RNN(input_size,hidden_size,num_layers, dropout=0.5)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        out,hidden = self.rnn(input.view(1,1,-1),hidden)\n",
    "        out = self.fc(out.view(1,-1))\n",
    "        return out,hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        hidden = Variable(torch.zeros(self.num_layers, 1, self.hidden_size)).cuda()\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(len(data[0]), 500, len(data[0]), 1).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19.4 Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 100\n",
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Iter [100/1627] Loss: 316.6672\n",
      "Epoch [1/5], Iter [200/1627] Loss: 329.9896\n",
      "Epoch [1/5], Iter [300/1627] Loss: 273.8569\n",
      "Epoch [1/5], Iter [400/1627] Loss: 246.0619\n",
      "Epoch [1/5], Iter [500/1627] Loss: 224.3812\n",
      "Epoch [1/5], Iter [600/1627] Loss: 246.5113\n",
      "Epoch [1/5], Iter [700/1627] Loss: 209.9599\n",
      "Epoch [1/5], Iter [800/1627] Loss: 232.5223\n",
      "Epoch [1/5], Iter [900/1627] Loss: 217.3411\n",
      "Epoch [1/5], Iter [1000/1627] Loss: 212.8072\n",
      "Epoch [1/5], Iter [1100/1627] Loss: 228.4046\n",
      "Epoch [1/5], Iter [1200/1627] Loss: 249.0327\n",
      "Epoch [1/5], Iter [1300/1627] Loss: 257.2166\n",
      "Epoch [1/5], Iter [1400/1627] Loss: 235.2767\n",
      "Epoch [1/5], Iter [1500/1627] Loss: 232.9294\n",
      "Epoch [1/5], Iter [1600/1627] Loss: 224.7668\n",
      "Epoch [2/5], Iter [100/1627] Loss: 205.2259\n",
      "Epoch [2/5], Iter [200/1627] Loss: 224.1319\n",
      "Epoch [2/5], Iter [300/1627] Loss: 208.9300\n",
      "Epoch [2/5], Iter [400/1627] Loss: 147.5427\n",
      "Epoch [2/5], Iter [500/1627] Loss: 237.7560\n",
      "Epoch [2/5], Iter [600/1627] Loss: 217.4826\n",
      "Epoch [2/5], Iter [700/1627] Loss: 204.1846\n",
      "Epoch [2/5], Iter [800/1627] Loss: 210.9026\n",
      "Epoch [2/5], Iter [900/1627] Loss: 219.6431\n",
      "Epoch [2/5], Iter [1000/1627] Loss: 194.0384\n",
      "Epoch [2/5], Iter [1100/1627] Loss: 214.3953\n",
      "Epoch [2/5], Iter [1200/1627] Loss: 206.8829\n",
      "Epoch [2/5], Iter [1300/1627] Loss: 226.7401\n",
      "Epoch [2/5], Iter [1400/1627] Loss: 218.3118\n",
      "Epoch [2/5], Iter [1500/1627] Loss: 212.3339\n",
      "Epoch [2/5], Iter [1600/1627] Loss: 243.2288\n",
      "Epoch [3/5], Iter [100/1627] Loss: 186.3408\n",
      "Epoch [3/5], Iter [200/1627] Loss: 232.0898\n",
      "Epoch [3/5], Iter [300/1627] Loss: 217.7713\n",
      "Epoch [3/5], Iter [400/1627] Loss: 181.8976\n",
      "Epoch [3/5], Iter [500/1627] Loss: 209.8988\n",
      "Epoch [3/5], Iter [600/1627] Loss: 231.6378\n",
      "Epoch [3/5], Iter [700/1627] Loss: 224.8250\n",
      "Epoch [3/5], Iter [800/1627] Loss: 230.5619\n",
      "Epoch [3/5], Iter [900/1627] Loss: 179.4484\n",
      "Epoch [3/5], Iter [1000/1627] Loss: 190.0935\n",
      "Epoch [3/5], Iter [1100/1627] Loss: 231.4825\n",
      "Epoch [3/5], Iter [1200/1627] Loss: 198.5265\n",
      "Epoch [3/5], Iter [1300/1627] Loss: 192.9525\n",
      "Epoch [3/5], Iter [1400/1627] Loss: 200.3611\n",
      "Epoch [3/5], Iter [1500/1627] Loss: 170.4281\n",
      "Epoch [3/5], Iter [1600/1627] Loss: 194.8066\n",
      "Epoch [4/5], Iter [100/1627] Loss: 178.2878\n",
      "Epoch [4/5], Iter [200/1627] Loss: 214.5259\n",
      "Epoch [4/5], Iter [300/1627] Loss: 217.6827\n",
      "Epoch [4/5], Iter [400/1627] Loss: 185.4678\n",
      "Epoch [4/5], Iter [500/1627] Loss: 183.2556\n",
      "Epoch [4/5], Iter [600/1627] Loss: 250.3773\n",
      "Epoch [4/5], Iter [700/1627] Loss: 175.2371\n",
      "Epoch [4/5], Iter [800/1627] Loss: 180.1927\n",
      "Epoch [4/5], Iter [900/1627] Loss: 192.2258\n",
      "Epoch [4/5], Iter [1000/1627] Loss: 186.7056\n",
      "Epoch [4/5], Iter [1100/1627] Loss: 203.3939\n",
      "Epoch [4/5], Iter [1200/1627] Loss: 223.8341\n",
      "Epoch [4/5], Iter [1300/1627] Loss: 227.6341\n",
      "Epoch [4/5], Iter [1400/1627] Loss: 216.9385\n",
      "Epoch [4/5], Iter [1500/1627] Loss: 178.9773\n",
      "Epoch [4/5], Iter [1600/1627] Loss: 218.7803\n",
      "Epoch [5/5], Iter [100/1627] Loss: 190.3456\n",
      "Epoch [5/5], Iter [200/1627] Loss: 222.5777\n",
      "Epoch [5/5], Iter [300/1627] Loss: 226.7133\n",
      "Epoch [5/5], Iter [400/1627] Loss: 219.8720\n",
      "Epoch [5/5], Iter [500/1627] Loss: 215.5412\n",
      "Epoch [5/5], Iter [600/1627] Loss: 172.4505\n",
      "Epoch [5/5], Iter [700/1627] Loss: 214.1434\n",
      "Epoch [5/5], Iter [800/1627] Loss: 202.6140\n",
      "Epoch [5/5], Iter [900/1627] Loss: 201.9826\n",
      "Epoch [5/5], Iter [1000/1627] Loss: 172.7197\n",
      "Epoch [5/5], Iter [1100/1627] Loss: 171.8468\n",
      "Epoch [5/5], Iter [1200/1627] Loss: 200.6735\n",
      "Epoch [5/5], Iter [1300/1627] Loss: 173.3377\n",
      "Epoch [5/5], Iter [1400/1627] Loss: 187.2686\n",
      "Epoch [5/5], Iter [1500/1627] Loss: 172.6170\n",
      "Epoch [5/5], Iter [1600/1627] Loss: 186.7969\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    sp = list(range(0, len(data) - 2 * step, step))\n",
    "    sp = np.add(sp, random.randint(0, step))\n",
    "    random.shuffle(sp)\n",
    "    \n",
    "    for i in range(len(sp)) :\n",
    "    \n",
    "        hidden = model.init_hidden()\n",
    "\n",
    "        cost = 0\n",
    "\n",
    "        for pos in range(sp[i], sp[i] + step):\n",
    "            X = Variable(torch.from_numpy(data[pos]).type(torch.FloatTensor)).cuda()\n",
    "            y = torch.from_numpy(data[pos+1]).cuda()\n",
    "            _, y = y.max(dim=0)\n",
    "\n",
    "            pre, hidden = model(X,hidden)\n",
    "            cost += loss(pre,Variable(y).cuda())\n",
    "\n",
    "        cost.backward()\n",
    "        \n",
    "        nn.utils.clip_grad_norm(model.parameters(), 5)\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        if (i + 1) % 100 == 0 :\n",
    "            print('Epoch [%d/%d], Iter [%d/%d] Loss: %.4f'\n",
    "                     %(epoch+1, num_epochs, i + 1, len(sp), cost.data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19.5 Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Generated Text : \n",
      " To to but serf a drage tide thy worde a Matenn\n",
      "\n",
      "   Bam. The tow the thought that he my Lord, and with the mend is combetser,\n",
      "Hadsinge,\n",
      "And wothing tome of ich the bering\n",
      "\n",
      "   Goor. I so farle: will ghe this to the Spory?\n",
      "  Polin. Wist the bleay shall what all ay the within of ming our contor Kinge, If houe tid this wall tay teale.\n",
      "\n",
      "  Ham. That it, warthis indore of my Sorle mine forme and be make of in mand the Merame,\n",
      "Ile it thim this?\n",
      "Thim it the Singoued inder words why camast and in that? With\n"
     ]
    }
   ],
   "source": [
    "start_num = 1\n",
    "text = index2char[start_num]\n",
    "\n",
    "model.eval()\n",
    "hidden = model.init_hidden()\n",
    "\n",
    "X_test = Variable(torch.from_numpy(data[start_num]).type(torch.FloatTensor)).cuda()\n",
    "    \n",
    "for i in range(500) :\n",
    "\n",
    "    pre, hidden = model(X_test, hidden)\n",
    "\n",
    "    temp = pre.cpu().data.numpy()[0]\n",
    "\n",
    "    best_5 = np.argsort(temp)[::-1][:5]\n",
    "    \n",
    "    temp = np.exp(temp[best_5])\n",
    "    \n",
    "    temp = temp / temp.sum()\n",
    "    \n",
    "    pre = np.random.choice(best_5, 1, p = temp)[0]\n",
    "    \n",
    "    curr_char = index2char[pre]\n",
    "    \n",
    "    text += curr_char\n",
    "    \n",
    "    X_test = Variable(torch.from_numpy(char2vec[curr_char]).type(torch.FloatTensor)).cuda()\n",
    "    \n",
    "print(\"* Generated Text : \\n\", text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
