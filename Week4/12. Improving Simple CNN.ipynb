{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. Improving Simple CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "import torch.utils.data as Data\n",
    "import torch.nn.init as init\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.1 Preparing Custom Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ㄱ', 'ㄲ', 'ㄴ', 'ㄷ', 'ㄸ', 'ㄹ', 'ㅁ', 'ㅂ', 'ㅃ', 'ㅅ', 'ㅆ', 'ㅇ', 'ㅈ', 'ㅉ', 'ㅊ', 'ㅋ', 'ㅌ', 'ㅍ', 'ㅎ', 'ㅏ', 'ㅐ', 'ㅑ', 'ㅒ', 'ㅓ', 'ㅔ', 'ㅕ', 'ㅖ', 'ㅗ', 'ㅘ', 'ㅙ', 'ㅛ', 'ㅜ', 'ㅝ', 'ㅞ', 'ㅟ', 'ㅠ', 'ㅡ', 'ㅢ', 'ㅣ']\n",
      "{'ㄱ': 0, 'ㄲ': 1, 'ㄴ': 2, 'ㄷ': 3, 'ㄸ': 4, 'ㄹ': 5, 'ㅁ': 6, 'ㅂ': 7, 'ㅃ': 8, 'ㅅ': 9, 'ㅆ': 10, 'ㅇ': 11, 'ㅈ': 12, 'ㅉ': 13, 'ㅊ': 14, 'ㅋ': 15, 'ㅌ': 16, 'ㅍ': 17, 'ㅎ': 18, 'ㅏ': 19, 'ㅐ': 20, 'ㅑ': 21, 'ㅒ': 22, 'ㅓ': 23, 'ㅔ': 24, 'ㅕ': 25, 'ㅖ': 26, 'ㅗ': 27, 'ㅘ': 28, 'ㅙ': 29, 'ㅛ': 30, 'ㅜ': 31, 'ㅝ': 32, 'ㅞ': 33, 'ㅟ': 34, 'ㅠ': 35, 'ㅡ': 36, 'ㅢ': 37, 'ㅣ': 38}\n"
     ]
    }
   ],
   "source": [
    "img_dir = \"./data/jamo\"\n",
    "img_data = dsets.ImageFolder(img_dir, transforms.Compose([\n",
    "            transforms.Grayscale(),\n",
    "#           Data Augmentation\n",
    "#           transforms.RandomRotation(15)\n",
    "#           transforms.CenterCrop(28),\n",
    "#           transforms.Lambda(lambda x: x.rotate(15)),\n",
    "    \n",
    "#           Data Nomalization\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "            ]))\n",
    "\n",
    "#https://pytorch.org/docs/stable/torchvision/transforms.html\n",
    "\n",
    "print(img_data.classes)\n",
    "print(img_data.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "font_num = 720"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(data, train_ratio, stratify, stratify_num, batch_size) :\n",
    "    \n",
    "    length = len(data)\n",
    "    \n",
    "    if stratify :\n",
    "        label_num = int(len(data)/stratify_num)\n",
    "        cut = int(stratify_num*train_ratio)\n",
    "        train_indices = np.random.permutation(np.arange(stratify_num))[:cut]\n",
    "        test_indices = np.random.permutation(np.arange(stratify_num))[cut:]\n",
    "        \n",
    "        for i in range(1, label_num) :\n",
    "            train_indices = np.concatenate((train_indices, np.random.permutation(np.arange(stratify_num))[:cut] + stratify_num*i))\n",
    "            test_indices = np.concatenate((test_indices, np.random.permutation(np.arange(stratify_num))[cut:] + stratify_num*i))\n",
    "        \n",
    "    else :\n",
    "        cut = int(len(data)*train_ratio)\n",
    "        train_indices = np.random.permutation(np.arange(length))[:cut]\n",
    "        test_indices = np.random.permutation(np.arange(length))[cut:]\n",
    "        \n",
    "    np.random.shuffle(test_indices)\n",
    "    np.random.shuffle(train_indices)\n",
    "    \n",
    "    train_loader = Data.DataLoader(data, batch_size=batch_size, shuffle=False, sampler = train_indices, num_workers=1, drop_last = True)\n",
    "    test_loader = Data.DataLoader(data, batch_size=batch_size, shuffle=False, sampler = test_indices, num_workers=1, drop_last = True)\n",
    "\n",
    "    return train_loader, test_loader, len(train_indices), len(test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader, train_num, test_num = train_test_split(img_data, 0.8, True, font_num, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.2 Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Conv2d(1,16,5),\n",
    "            nn.ReLU(),\n",
    "            #Dropout\n",
    "            nn.Dropout2d(0.5),\n",
    "            nn.Conv2d(16,32,5),\n",
    "            #Batch Nomalization\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.Conv2d(32,64,5),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2)\n",
    "        )\n",
    "        \n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Linear(64*5*5,500),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(500,39)\n",
    "        )\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "#                 Weight Initialization\n",
    "#                 init.xavier_normal(m.weight.data)\n",
    "                init.kaiming_normal(m.weight.data)\n",
    "                m.bias.data.fill_(0)\n",
    "        \n",
    "            elif isinstance(m, nn.Linear):\n",
    "                init.kaiming_normal(m.weight.data)\n",
    "                m.bias.data.fill_(0)                \n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.layer(x)\n",
    "        out = out.view(batch_size,-1)\n",
    "        out = self.fc_layer(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "model = CNN().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss() # Loss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Momentum & Weight Regularization(L2)\n",
    "# optim.SGD(model.parameters(), lr=1e-2, momentum=0.9, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model() :\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in test_loader:\n",
    "\n",
    "        images = Variable(images).cuda()\n",
    "        outputs = model(images)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels.cuda()).sum()\n",
    "\n",
    "    print('Accuracy of test images: %f %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], lter [100/224], Loss: 0.7463\n",
      "Accuracy of test images: 72.892857 %\n",
      "Epoch [1/50], lter [200/224], Loss: 0.4524\n",
      "Accuracy of test images: 81.821429 %\n",
      "Epoch [2/50], lter [100/224], Loss: 0.2912\n",
      "Accuracy of test images: 86.982143 %\n",
      "Epoch [2/50], lter [200/224], Loss: 0.2548\n",
      "Accuracy of test images: 87.035714 %\n",
      "Epoch [3/50], lter [100/224], Loss: 0.2339\n",
      "Accuracy of test images: 90.446429 %\n",
      "Epoch [3/50], lter [200/224], Loss: 0.1254\n",
      "Accuracy of test images: 92.982143 %\n",
      "Epoch [4/50], lter [100/224], Loss: 0.0695\n",
      "Accuracy of test images: 92.178571 %\n",
      "Epoch [4/50], lter [200/224], Loss: 0.2028\n",
      "Accuracy of test images: 95.107143 %\n",
      "Epoch [5/50], lter [100/224], Loss: 0.1206\n",
      "Accuracy of test images: 96.392857 %\n",
      "Epoch [5/50], lter [200/224], Loss: 0.0541\n",
      "Accuracy of test images: 97.142857 %\n",
      "Epoch [6/50], lter [100/224], Loss: 0.0734\n",
      "Accuracy of test images: 97.732143 %\n",
      "Epoch [6/50], lter [200/224], Loss: 0.1048\n",
      "Accuracy of test images: 97.339286 %\n",
      "Epoch [7/50], lter [100/224], Loss: 0.0641\n",
      "Accuracy of test images: 96.982143 %\n",
      "Epoch [7/50], lter [200/224], Loss: 0.0514\n",
      "Accuracy of test images: 98.357143 %\n",
      "Epoch [8/50], lter [100/224], Loss: 0.0575\n",
      "Accuracy of test images: 98.089286 %\n",
      "Epoch [8/50], lter [200/224], Loss: 0.0194\n",
      "Accuracy of test images: 98.392857 %\n",
      "Epoch [9/50], lter [100/224], Loss: 0.0116\n",
      "Accuracy of test images: 97.000000 %\n",
      "Epoch [9/50], lter [200/224], Loss: 0.0129\n",
      "Accuracy of test images: 98.321429 %\n",
      "Epoch [10/50], lter [100/224], Loss: 0.0631\n",
      "Accuracy of test images: 99.035714 %\n",
      "Epoch [10/50], lter [200/224], Loss: 0.0147\n",
      "Accuracy of test images: 98.625000 %\n",
      "Epoch [11/50], lter [100/224], Loss: 0.0122\n",
      "Accuracy of test images: 98.696429 %\n",
      "Epoch [11/50], lter [200/224], Loss: 0.0771\n",
      "Accuracy of test images: 98.732143 %\n",
      "Epoch [12/50], lter [100/224], Loss: 0.0771\n",
      "Accuracy of test images: 98.214286 %\n",
      "Epoch [12/50], lter [200/224], Loss: 0.0272\n",
      "Accuracy of test images: 98.875000 %\n",
      "Epoch [13/50], lter [100/224], Loss: 0.0130\n",
      "Accuracy of test images: 98.946429 %\n",
      "Epoch [13/50], lter [200/224], Loss: 0.0279\n",
      "Accuracy of test images: 98.946429 %\n",
      "Epoch [14/50], lter [100/224], Loss: 0.0099\n",
      "Accuracy of test images: 99.250000 %\n",
      "Epoch [14/50], lter [200/224], Loss: 0.0240\n",
      "Accuracy of test images: 98.982143 %\n",
      "Epoch [15/50], lter [100/224], Loss: 0.0182\n",
      "Accuracy of test images: 99.375000 %\n",
      "Epoch [15/50], lter [200/224], Loss: 0.0121\n",
      "Accuracy of test images: 99.375000 %\n",
      "Epoch [16/50], lter [100/224], Loss: 0.0093\n",
      "Accuracy of test images: 99.428571 %\n",
      "Epoch [16/50], lter [200/224], Loss: 0.0054\n",
      "Accuracy of test images: 99.053571 %\n",
      "Epoch [17/50], lter [100/224], Loss: 0.0030\n",
      "Accuracy of test images: 99.375000 %\n",
      "Epoch [17/50], lter [200/224], Loss: 0.0032\n",
      "Accuracy of test images: 99.107143 %\n",
      "Epoch [18/50], lter [100/224], Loss: 0.0144\n",
      "Accuracy of test images: 99.607143 %\n",
      "Epoch [18/50], lter [200/224], Loss: 0.0748\n",
      "Accuracy of test images: 98.446429 %\n",
      "Epoch [19/50], lter [100/224], Loss: 0.0295\n",
      "Accuracy of test images: 99.250000 %\n",
      "Epoch [19/50], lter [200/224], Loss: 0.0192\n",
      "Accuracy of test images: 99.321429 %\n",
      "Epoch [20/50], lter [100/224], Loss: 0.1362\n",
      "Accuracy of test images: 99.071429 %\n",
      "Epoch [20/50], lter [200/224], Loss: 0.0107\n",
      "Accuracy of test images: 99.428571 %\n",
      "Epoch [21/50], lter [100/224], Loss: 0.0117\n",
      "Accuracy of test images: 99.625000 %\n",
      "Epoch [21/50], lter [200/224], Loss: 0.0019\n",
      "Accuracy of test images: 99.482143 %\n",
      "Epoch [22/50], lter [100/224], Loss: 0.0038\n",
      "Accuracy of test images: 99.428571 %\n",
      "Epoch [22/50], lter [200/224], Loss: 0.0032\n",
      "Accuracy of test images: 99.250000 %\n",
      "Epoch [23/50], lter [100/224], Loss: 0.0015\n",
      "Accuracy of test images: 99.500000 %\n",
      "Epoch [23/50], lter [200/224], Loss: 0.0014\n",
      "Accuracy of test images: 99.464286 %\n",
      "Epoch [24/50], lter [100/224], Loss: 0.0015\n",
      "Accuracy of test images: 99.553571 %\n",
      "Epoch [24/50], lter [200/224], Loss: 0.0088\n",
      "Accuracy of test images: 99.339286 %\n",
      "Epoch [25/50], lter [100/224], Loss: 0.0003\n",
      "Accuracy of test images: 99.500000 %\n",
      "Epoch [25/50], lter [200/224], Loss: 0.0066\n",
      "Accuracy of test images: 99.107143 %\n",
      "Epoch [26/50], lter [100/224], Loss: 0.0005\n",
      "Accuracy of test images: 99.589286 %\n",
      "Epoch [26/50], lter [200/224], Loss: 0.0015\n",
      "Accuracy of test images: 99.500000 %\n",
      "Epoch [27/50], lter [100/224], Loss: 0.0998\n",
      "Accuracy of test images: 99.625000 %\n",
      "Epoch [27/50], lter [200/224], Loss: 0.0065\n",
      "Accuracy of test images: 99.517857 %\n",
      "Epoch [28/50], lter [100/224], Loss: 0.0027\n",
      "Accuracy of test images: 99.589286 %\n",
      "Epoch [28/50], lter [200/224], Loss: 0.0058\n",
      "Accuracy of test images: 99.589286 %\n",
      "Epoch [29/50], lter [100/224], Loss: 0.0009\n",
      "Accuracy of test images: 99.642857 %\n",
      "Epoch [29/50], lter [200/224], Loss: 0.0006\n",
      "Accuracy of test images: 99.517857 %\n",
      "Epoch [30/50], lter [100/224], Loss: 0.0016\n",
      "Accuracy of test images: 99.321429 %\n",
      "Epoch [30/50], lter [200/224], Loss: 0.0135\n",
      "Accuracy of test images: 99.410714 %\n",
      "Epoch [31/50], lter [100/224], Loss: 0.0010\n",
      "Accuracy of test images: 99.553571 %\n",
      "Epoch [31/50], lter [200/224], Loss: 0.0009\n",
      "Accuracy of test images: 99.535714 %\n",
      "Epoch [32/50], lter [100/224], Loss: 0.0011\n",
      "Accuracy of test images: 98.946429 %\n",
      "Epoch [32/50], lter [200/224], Loss: 0.0532\n",
      "Accuracy of test images: 99.535714 %\n",
      "Epoch [33/50], lter [100/224], Loss: 0.0025\n",
      "Accuracy of test images: 99.571429 %\n",
      "Epoch [33/50], lter [200/224], Loss: 0.0004\n",
      "Accuracy of test images: 99.625000 %\n",
      "Epoch [34/50], lter [100/224], Loss: 0.0002\n",
      "Accuracy of test images: 99.678571 %\n",
      "Epoch [34/50], lter [200/224], Loss: 0.0006\n",
      "Accuracy of test images: 99.696429 %\n",
      "Epoch [35/50], lter [100/224], Loss: 0.0004\n",
      "Accuracy of test images: 99.678571 %\n",
      "Epoch [35/50], lter [200/224], Loss: 0.0003\n",
      "Accuracy of test images: 99.589286 %\n",
      "Epoch [36/50], lter [100/224], Loss: 0.0001\n",
      "Accuracy of test images: 99.642857 %\n",
      "Epoch [36/50], lter [200/224], Loss: 0.0016\n",
      "Accuracy of test images: 99.678571 %\n",
      "Epoch [37/50], lter [100/224], Loss: 0.0001\n",
      "Accuracy of test images: 99.482143 %\n",
      "Epoch [37/50], lter [200/224], Loss: 0.0003\n",
      "Accuracy of test images: 99.339286 %\n",
      "Epoch [38/50], lter [100/224], Loss: 0.0029\n",
      "Accuracy of test images: 99.482143 %\n",
      "Epoch [38/50], lter [200/224], Loss: 0.0032\n",
      "Accuracy of test images: 99.607143 %\n",
      "Epoch [39/50], lter [100/224], Loss: 0.0077\n",
      "Accuracy of test images: 99.517857 %\n",
      "Epoch [39/50], lter [200/224], Loss: 0.0093\n",
      "Accuracy of test images: 99.410714 %\n",
      "Epoch [40/50], lter [100/224], Loss: 0.0003\n",
      "Accuracy of test images: 99.553571 %\n",
      "Epoch [40/50], lter [200/224], Loss: 0.0004\n",
      "Accuracy of test images: 99.553571 %\n",
      "Epoch [41/50], lter [100/224], Loss: 0.0014\n",
      "Accuracy of test images: 99.517857 %\n",
      "Epoch [41/50], lter [200/224], Loss: 0.0002\n",
      "Accuracy of test images: 99.678571 %\n",
      "Epoch [42/50], lter [100/224], Loss: 0.0007\n",
      "Accuracy of test images: 99.464286 %\n",
      "Epoch [42/50], lter [200/224], Loss: 0.0001\n",
      "Accuracy of test images: 99.660714 %\n",
      "Epoch [43/50], lter [100/224], Loss: 0.0018\n",
      "Accuracy of test images: 99.446429 %\n",
      "Epoch [43/50], lter [200/224], Loss: 0.0008\n",
      "Accuracy of test images: 99.571429 %\n",
      "Epoch [44/50], lter [100/224], Loss: 0.0044\n",
      "Accuracy of test images: 99.660714 %\n",
      "Epoch [44/50], lter [200/224], Loss: 0.0004\n",
      "Accuracy of test images: 99.678571 %\n",
      "Epoch [45/50], lter [100/224], Loss: 0.0003\n",
      "Accuracy of test images: 99.625000 %\n",
      "Epoch [45/50], lter [200/224], Loss: 0.0049\n",
      "Accuracy of test images: 99.571429 %\n",
      "Epoch [46/50], lter [100/224], Loss: 0.0002\n",
      "Accuracy of test images: 99.607143 %\n",
      "Epoch [46/50], lter [200/224], Loss: 0.0003\n",
      "Accuracy of test images: 99.500000 %\n",
      "Epoch [47/50], lter [100/224], Loss: 0.0001\n",
      "Accuracy of test images: 99.589286 %\n",
      "Epoch [47/50], lter [200/224], Loss: 0.0026\n",
      "Accuracy of test images: 99.535714 %\n",
      "Epoch [48/50], lter [100/224], Loss: 0.0004\n",
      "Accuracy of test images: 99.607143 %\n",
      "Epoch [48/50], lter [200/224], Loss: 0.0164\n",
      "Accuracy of test images: 99.642857 %\n",
      "Epoch [49/50], lter [100/224], Loss: 0.0023\n",
      "Accuracy of test images: 99.017857 %\n",
      "Epoch [49/50], lter [200/224], Loss: 0.0010\n",
      "Accuracy of test images: 99.482143 %\n",
      "Epoch [50/50], lter [100/224], Loss: 0.0004\n",
      "Accuracy of test images: 99.607143 %\n",
      "Epoch [50/50], lter [200/224], Loss: 0.0006\n",
      "Accuracy of test images: 99.642857 %\n"
     ]
    }
   ],
   "source": [
    "# Learning Rate Scheduler\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "#scheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma= 0.99)\n",
    "#scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=[10,30,80], gamma= 0.1)\n",
    "scheduler = lr_scheduler.ExponentialLR(optimizer, gamma= 0.99)\n",
    "#scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    scheduler.step()\n",
    "    for i, (batch_images, batch_labels) in enumerate(train_loader):\n",
    "        \n",
    "        X = Variable(batch_images).cuda()\n",
    "        Y = Variable(batch_labels).cuda()\n",
    "\n",
    "        pre = model(X)\n",
    "        cost = loss(pre, Y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print('Epoch [%d/%d], lter [%d/%d], Loss: %.4f'\n",
    "                 %(epoch+1, num_epochs, i+1, train_num//batch_size, cost.data[0]))\n",
    "            test_model()\n",
    "            model.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
